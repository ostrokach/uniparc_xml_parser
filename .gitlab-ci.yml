default:
  image: condaforge/linux-anvil-cos7-x86_64:latest

stages:
  - build
  - test
  - deploy

# === Variables ===

variables:
  PACKAGE_VERSION: 0.1.3

# === Configurations ===

.skip-custom-pipelines:
  except:
    variables:
      - $UPDATE_TABLES

.configure:
  extends:
    - .skip-custom-pipelines
  before_script:
    # Rust
    - curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
    - source $HOME/.cargo/env
    # Conda
    - |
      cat <<EOF > ~/.condarc
      channel_priority: true
      channels:
        - ostrokach-forge
        - conda-forge
        - defaults
      EOF
    - conda update -yq conda

# === Build ===

build:
  stage: build
  extends:
    - .configure
  script:
    - mkdir -p "${CI_PROJECT_DIR}/conda-bld"
    - conda build "${CI_PROJECT_DIR}/.conda" --output-folder "${CI_PROJECT_DIR}/conda-bld"
  artifacts:
    paths:
      - conda-bld

# === Test ===

test:
  stage: test
  extends:
    - .configure
  dependencies:
    - build
  script:
    # Create conda environment for testing
    - conda update -yq conda
    - conda create -n test -q -c file://${CI_PROJECT_DIR}/conda-bld --strict-channel-priority
      "python=3.9" ${CI_PROJECT_NAME} pytest || true
    - conda activate test
    # Run tests
    - uniparc_xml_parser --help
    # - python -m pytest -c setup.cfg --color=yes "tests/"
    # Save binary for later
    - mkdir package/
    - cp $(which uniparc_xml_parser) package/
  artifacts:
    paths:
      - package/

# download:
#   stage: download
#   script:
#     - 'wget --header="JOB-TOKEN: $CI_JOB_TOKEN" ${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/my_package/0.0.1/file.txt'

# === Pages ===

pages:
  stage: test
  extends:
    - .configure
  dependencies:
    - build
  script:
    # Conda install
    - cp -r $CI_PROJECT_DIR/conda-bld/* /opt/conda/conda-bld/
    - conda index /opt/conda/conda-bld/
    - conda install -yq --use-local "python=$PYTHON_VERSION" $CI_PROJECT_NAME
    # Build docs
    - conda install -yq nbconvert ipython ipykernel pandoc
    - pip install -q sphinx sphinx_rtd_theme recommonmark nbsphinx
    - sphinx-build docs public
  dependencies:
    - build
  artifacts:
    paths:
      - public

# === Deploy ===

deploy:
  stage: deploy
  extends:
    - .configure
  script:
    # Upload to cargo
    - cargo publish
    # Upload to generic package registry
    - curl --header "JOB-TOKEN: $CI_JOB_TOKEN" --upload-file $CI_PROJECT_DIR/package/uniparc_xml_parser
      "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/packages/generic/${CI_PROJECT_NAME}/${PACKAGE_VERSION}/uniparc_xml_parser"
    # Upload to anaconda
    - anaconda -t $ANACONDA_TOKEN upload $CI_PROJECT_DIR/conda-bld/*/*.tar.bz2 -u ostrokach-forge --no-progress
  dependencies:
    - build
  only:
    - tags

# === Run pipeline ===

run-pipeline:
  image: ubuntu:20.04
  before_script:
    # Install global dependencies
    - apt-get update -y -qq -o=Dpkg::Use-Pty=0
    - apt-get install -y -qq -o=Dpkg::Use-Pty=0 curl openssl gzip gettext-base
    # Install ssh client
    - "which ssh-agent || ( apt-get install -y -qq -o=Dpkg::Use-Pty=0 openssh-client -y )"
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
    - echo "$KNOWN_HOSTS" >> ~/.ssh/known_hosts
    # Test that ssh client works
    - ssh strokach@conda-envs.proteinsolver.org "echo hello"
    # Install gcloud
    - echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
    - apt-get install -y -qq -o=Dpkg::Use-Pty=0 apt-transport-https ca-certificates gnupg
    - curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -
    - apt-get update -y -qq -o=Dpkg::Use-Pty=0
    - apt-get install -y -qq -o=Dpkg::Use-Pty=0 google-cloud-sdk
    - gcloud --version
    # Install conda
    - |
      cat <<EOF > ~/.condarc
      channel_priority: strict
      channels:
        - ostrokach-forge
        - conda-forge
        - defaults
      EOF
    - curl -s -L https://github.com/conda-forge/miniforge/releases/download/4.9.2-5/Mambaforge-4.9.2-5-Linux-x86_64.sh > miniconda.sh
    - openssl dgst -sha256 miniconda.sh | grep 7f0ad0c2f367751f7878d25a7bc1b4aa48b8dcea864daf9bc09acb595102368b
    - sh miniconda.sh -b -p /opt/conda
    - source /opt/conda/etc/profile.d/conda.sh
  script:
    - conda activate base
    - mamba install 'python=3.9' pyarrow uniparc-xml-parser
    - mkdir output
    - cd output
    - curl -sS ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/uniparc/uniparc_all.xml.gz | zcat | uniparc_xml_parser
    - python ../scripts/tsv_to_parquet.py *.tsv
    # Upload Parquet files to our server
    - rsync -rv --info=progress2 -p --chmod=ug=rwX,o=rX *.parquet strokach@conda-envs.proteinsolver.org:/share/uniparc/
    # Update BigQuery tables
    - bq load --replace --clustering_fields uniparc_id uniparc.parquet
    - bq load --replace --clustering_fields database,uniparc_id domain.parquet
    - bq load --replace --clustering_fields database,uniparc_id domain.parquet
  only:
    variables:
      - $UPDATE_TABLES
